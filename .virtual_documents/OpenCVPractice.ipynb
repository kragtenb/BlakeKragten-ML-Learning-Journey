





import cv2 as cv
import matplotlib.pyplot as plt


image_file = '/home/blake/SelfDriving-RC-deep-learning/TrainingData/Images/2024_03_25_T_11_08_55.jpg'
image = cv.imread(image_file)

# If your image is in BGR format (OpenCV default), convert it to RGB for matplotlib
#if image.shape[2] == 3:
#  image = cv.cvtColor(image, cv.COLOR_BGR2RGB)

def display_image(image):
  plt.imshow(cv.cvtColor(image, cv.COLOR_BGR2RGB))
  plt.show()

# Display the image
plt.imshow(image)
plt.show()


image_file = '/home/blake/SelfDriving-RC-deep-learning/TrainingData/Images/2024_03_25_T_11_05_58.jpg'
image = cv.imread(image_file)

# resize the image to half
image_height = int(image.shape[0] / 2)
image_width = int(image.shape[1] / 2)
resized = cv.resize(image, (image_width, image_height))

# Resize to half the original size
half_size_image = cv.resize(image, (0, 0), fx=2, fy=2)

# plt.imshow(resized)
plt.imshow(half_size_image)
plt.show()


# Crop image

# Top left corner
cropped_image = image[:image.shape[0]//4, :image.shape[1]//4,:]


display_image(cropped_image)





resized_area = cv.resize(image, (image.shape[1]//8, image.shape[0]//8), interpolation=cv.INTER_AREA)

plt.imshow(resized_area)
plt.show()


resized_linear = cv.resize(image, (image.shape[1]//8, image.shape[0]//8), interpolation=cv.INTER_LINEAR)

plt.imshow(resized_linear)
plt.show()





flip_0 = cv.flip(image, 0)
flip_1 = cv.flip(image, 1)
flip_neg_1 = cv.flip(image, -1)

plt.title("Flip Upside Down")
plt.imshow(flip_0)
plt.show()
plt.title("Flip left to right")
plt.imshow(flip_1)
plt.show()
plt.title("Flip both left to right and upsidedown")
plt.imshow(flip_neg_1)
plt.show()








rotation_matrix = cv.getRotationMatrix2D((image.shape[1]//2, image.shape[0]//2), 45, 1)
rotated_image = cv.warpAffine(image, rotation_matrix, (image.shape[1], image.shape[0]))
plt.imshow(rotated_image)
plt.title("Rotated Image")
plt.show()





grayscale_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)

plt.title("Greyscale")
display_image(grayscale_image)





hsv_image = cv.cvtColor(image, cv.COLOR_BGR2HSV)
plt.title("HSV Image BGR2HSV")
plt.imshow(hsv_image)
plt.show()

hsv_image = cv.cvtColor(cv.cvtColor(image, cv.COLOR_BGR2RGB), cv.COLOR_RGB2HSV)
plt.title("HSV Image RGB2HSV")
plt.imshow(hsv_image)
plt.show()


import cv2
import numpy as np
import matplotlib.pyplot as plt

# Create a gradient test image
test_image = np.linspace(0, 255, 256).astype('uint8')
test_image = np.tile(test_image, (256, 1))

# Calculate gradients using Sobel filters
sobelx = cv2.Sobel(test_image, cv2.CV_64F, 1, 0, ksize=3)  # Horizontal gradients
sobely = cv2.Sobel(test_image, cv2.CV_64F, 0, 1, ksize=3)  # Vertical gradients

# Calculate gradient magnitude
magnitude = np.sqrt(sobelx**2 + sobely**2)

# Visualize results
plt.figure(figsize=(10, 6))

plt.subplot(221), plt.imshow(test_image, cmap='gray'), plt.title('Original')
plt.subplot(222), plt.imshow(sobelx, cmap='gray'), plt.title('Sobel X')
plt.subplot(223), plt.imshow(sobely, cmap='gray'), plt.title('Sobel Y')
plt.subplot(224), plt.imshow(magnitude, cmap='gray'), plt.title('Gradient Magnitude')
plt.show()






salt_n_pepper_image = cv.imread("Images/salt_n_pepper_noise.png")
display_image(salt_n_pepper_image)


fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 15))
gaussian_blurred_image_3x3 = cv.GaussianBlur(salt_n_pepper_image, (3, 3), 0)
gaussian_blurred_image_5x5 = cv.GaussianBlur(salt_n_pepper_image, (5, 5), 0)
gaussian_blurred_image_7x7 = cv.GaussianBlur(salt_n_pepper_image, (7, 7), 0)
axes[0,0].set_title("gaussian_blurred_image_3x3")
axes[0,0].imshow(gaussian_blurred_image_3x3)
axes[0,1].set_title("gaussian_blurred_image_5x5")
axes[0,1].imshow(gaussian_blurred_image_5x5)
axes[1,0].set_title("gaussian_blurred_image_7x7")
axes[1,0].imshow(gaussian_blurred_image_7x7)

plt.tight_layout()
plt.show()





fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 15))
median_blurred_image_3x3 = cv.medianBlur(salt_n_pepper_image, 3)
median_blurred_image_5x5 = cv.medianBlur(salt_n_pepper_image, 5)
median_blurred_image_7x7 = cv.medianBlur(salt_n_pepper_image, 7)
axes[0,0].set_title("median_blurred_image_3x3")
axes[0,0].imshow(median_blurred_image_3x3)
axes[0,1].set_title("median_blurred_image_5x5")
axes[0,1].imshow(median_blurred_image_5x5)
axes[1,0].set_title("median_blurred_image_7x7")
axes[1,0].imshow(median_blurred_image_7x7)

plt.tight_layout()
plt.show()





fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(15, 20))
bilateral_75 = cv.bilateralFilter(salt_n_pepper_image, d=9, sigmaColor=75, sigmaSpace=75)
bilateral_75_d_25 = cv.bilateralFilter(salt_n_pepper_image, d=25, sigmaColor=75, sigmaSpace=75)
bilateral_150 = cv.bilateralFilter(salt_n_pepper_image, d=9, sigmaColor=150, sigmaSpace=150)
bilateral_35 = cv.bilateralFilter(salt_n_pepper_image, d=9, sigmaColor=35, sigmaSpace=35)
bilateral_75_150 = cv.bilateralFilter(salt_n_pepper_image, d=9, sigmaColor=75, sigmaSpace=150)
bilateral_150_75 = cv.bilateralFilter(salt_n_pepper_image, d=9, sigmaColor=150, sigmaSpace=75)
axes[0,0].set_title("bilateral_75")
axes[0,0].imshow(bilateral_75)
axes[0,1].set_title("bilateral_75_d_25")
axes[0,1].imshow(bilateral_75_d_25)
axes[1,0].set_title("bilateral_150")
axes[1,0].imshow(bilateral_150)
axes[1,1].set_title("bilateral_35")
axes[1,1].imshow(bilateral_35)
axes[2,0].set_title("bilateral_75_150")
axes[2,0].imshow(bilateral_75_150)
axes[2,1].set_title("bilateral_150_75")
axes[2,1].imshow(bilateral_150_75)

plt.tight_layout()
plt.show()








architecture_image = cv.imread("Images/architecture_drawing.png")
architecture_image = cv.cvtColor(architecture_image, cv.COLOR_BGR2RGB)
plt.imshow(architecture_image)
plt.show()


fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(10,15))
gaussian_blurred_arch_image_1 = cv.GaussianBlur(architecture_image, (1, 1), 0)
gaussian_blurred_arch_image_3 = cv.GaussianBlur(architecture_image, (3, 3), 0)
gaussian_blurred_arch_image_5 = cv.GaussianBlur(architecture_image, (5, 5), 0)
gaussian_blurred_arch_image_7 = cv.GaussianBlur(architecture_image, (7, 7), 0)
gaussian_blurred_arch_image_9 = cv.GaussianBlur(architecture_image, (9, 9), 0)
axes[0,0].set_title("Original")
axes[0,0].imshow(architecture_image)
axes[0,1].set_title("1x1")
axes[0,1].imshow(gaussian_blurred_arch_image_1)
axes[1,0].set_title("3x3")
axes[1,0].imshow(gaussian_blurred_arch_image_3)
axes[1,1].set_title("5x5")
axes[1,1].imshow(gaussian_blurred_arch_image_5)
axes[2,0].set_title("7x7")
axes[2,0].imshow(gaussian_blurred_arch_image_7)
axes[2,1].set_title("9x9")
axes[2,1].imshow(gaussian_blurred_arch_image_9)

plt.tight_layout
plt.show()


rc_image = cv.imread("TrainingData/Images/2024_03_25_T_11_09_06.jpg")
rc_image = cv.cvtColor(rc_image, cv.COLOR_BGR2GRAY)

display_image(rc_image)





blurred_rc_image = cv.GaussianBlur(rc_image, (9,9), 0)

display_image(blurred_rc_image)





# Calculate the gradients using Sobel filters
sobelx = cv2.Sobel(blurred_rc_image, cv2.CV_64F, 1, 0, ksize=5)
sobely = cv2.Sobel(blurred_rc_image, cv2.CV_64F, 0, 1, ksize=5)

# Define the Roberts kernels
kernel_x = np.array([[0, 1], [-1, 0]])
kernel_y = np.array([[1, 0], [0, -1]])

# Apply filtering. This remains the same as with Prewitt
roberts_x = cv2.filter2D(blurred_rc_image, -1, kernel_x)
roberts_y = cv2.filter2D(blurred_rc_image, -1, kernel_y)

# Define the Prewitt kernels (replace with Roberts kernels if desired)
kernel_x = np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]])
kernel_y = np.array([[-1, -1, -1], [0, 0, 0], [1, 1, 1]])

# Apply filtering (similar to using cv2.Sobel)
prewitt_x = cv2.filter2D(blurred_rc_image, -1, kernel_x)
prewitt_y = cv2.filter2D(blurred_rc_image, -1, kernel_y)

# Optionally calculate the magnitude of the gradient
magnitude = np.sqrt(sobelx**2 + sobely**2)  

# Visualize results
plt.figure(figsize=(10, 6))

plt.subplot(421), plt.imshow(blurred_rc_image, cmap='gray'), plt.title('Original')
plt.subplot(422), plt.imshow(sobelx, cmap='gray'), plt.title('Sobel X')
plt.subplot(423), plt.imshow(sobely, cmap='gray'), plt.title('Sobel Y')
plt.subplot(424), plt.imshow(roberts_x, cmap='gray'), plt.title('Roberts X')
plt.subplot(425), plt.imshow(roberts_y, cmap='gray'), plt.title('Roberts Y')
plt.subplot(426), plt.imshow(prewitt_x, cmap='gray'), plt.title('Prewitt X')
plt.subplot(427), plt.imshow(prewitt_y, cmap='gray'), plt.title('Prewitt Y')
plt.subplot(428), plt.imshow(magnitude, cmap='gray'), plt.title('Gradient Magnitude')
plt.show()


canny_edges = cv.Canny(blurred_rc_image, 40, 80)

fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10,10))

axes[0].set_title("Original")
axes[0].imshow(rc_image)

axes[1].set_title("Canny Edges")
axes[1].imshow(canny_edges)

plt.tight_layout()
plt.show()

















import os

images = []
images_path = "TrainingData/Images"
for im in os.listdir(images_path):
    if im.endswith(".jpg"):
        images.append(cv.imread(images_path + "/" + im))

images = np.array(images)


import cv2 as cv
import numpy as np
from matplotlib import pyplot as plt

def display_sift(img):
    img_copy = img.copy()
    # Convert greyscale
    grey_img = cv.cvtColor(img_copy, cv.COLOR_BGR2GRAY)
    
    # Create a SIFT object
    sift = cv.SIFT_create()
    
    # Detect keypoints and compute descriptors
    keypoints, descriptors = sift.detectAndCompute(grey_img, None)
    
    # Draw keypoints on the image
    img_copy = cv2.drawKeypoints(grey_img, keypoints, img_copy, flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)

    # print(descriptors.shape)
    # plt.imshow(img_copy)
    # plt.show()
    return keypoints, descriptors, img_copy

display_sift(images[0])


display_sift(images[3])








def display_orb(img):
    img_copy = img.copy()
    # Convert greyscale
    grey_img = cv.cvtColor(img_copy, cv.COLOR_BGR2GRAY)
    
    # Create a SIFT object
    orb = cv.ORB_create()
    
    # Detect keypoints and compute descriptors
    keypoints, descriptors = orb.detectAndCompute(grey_img, None)
    
    # Draw keypoints on the image
    img_copy = cv.drawKeypoints(grey_img, keypoints, img_copy, flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)

    # print(descriptors.shape)
    # plt.imshow(img_copy)
    # plt.show()
    return keypoints, descriptors, img_copy

display_orb(images[0])
display_sift(images[0])





img_1_keypts, img_1_desc, img_1 = display_sift(images[11])
img_2_keypts, img_2_desc, img_2 = display_sift(images[4])

img_1_orb_keypts, img_1_orb_desc, img_orb_1 = display_orb(images[11])
img_2_orb_keypts, img_2_orb_desc, img_orb_2 = display_orb(images[4])

# create BFMatcher Object

# NORM_HAMMING when using ORB
bf = cv.BFMatcher(cv.NORM_HAMMING, crossCheck = True)

# Match descriptors.
matches = bf.match(img_1_orb_desc, img_2_orb_desc)

# Sort them in the order of their distance.
matches = sorted(matches, key = lambda x:x.distance)


 
# Draw first 10 matches.
img3 = cv.drawMatches(images[11],img_1_orb_keypts,images[4],img_2_orb_keypts,matches[:10],None,flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)

display_image(img3)


# SIFT matcher
bf = cv.BFMatcher()

matches = bf.knnMatch(img_1_desc, img_2_desc, k=2)

# Apply ratio test
good = []
for m, n in matches:
    if m.distance < 0.6 * n.distance:
        good.append([m])

sift_img3 = cv.drawMatchesKnn(images[11], img_1_keypts, images[4], img_2_keypts, good, None, flags= cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)

display_image(sift_img3)


# FLANN

img1 = cv.imread("Images/bookbinding.png")
img2 = cv.imread("Images/PXL_20240406_214800868.jpg")

kpts, desc, sift = display_sift(img1)
kpts2, desc2, sift2 = display_sift(img2)

img1 = cv.cvtColor(img1, cv.COLOR_BGR2GRAY)
img2 = cv.cvtColor(img2, cv.COLOR_BGR2GRAY)

MIN_MATCH_COUNT = 10

FLANN_INDEX_KDTREE = 1
index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)
search_params = dict(checks=50)

flann = cv.FlannBasedMatcher(index_params, search_params)

matches = flann.knnMatch(desc, desc2, k=2)
 
# store all the good matches as per Lowe's ratio test.
good = []
for m,n in matches:
 if m.distance < 0.7*n.distance:
     good.append(m)

if len(good)>MIN_MATCH_COUNT:
    src_pts = np.float32([ kpts[m.queryIdx].pt for m in good ]).reshape(-1,1,2)
    dst_pts = np.float32([ kpts2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)
    
    M, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC,5.0)
    matchesMask = mask.ravel().tolist()
    
    h,w = img1.shape
    pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)
    print(pts)
    dst = cv.perspectiveTransform(pts,M)

    x_min = int(np.min(dst[:, :, 0]))
    x_max = int(np.max(dst[:, :, 0]))
    y_min = int(np.min(dst[:, :, 1]))
    y_max = int(np.max(dst[:, :, 1]))

    img2 = cv2.rectangle(img2, (x_min, y_min), (x_max, y_max), color=(255, 255, 255), thickness=50)

    # img2 = cv.polylines(img2,[np.int32(dst)],True,255,10, cv.LINE_AA)
 
else:
    print( "Not enough matches are found - {}/{}".format(len(good), MIN_MATCH_COUNT) )
    matchesMask = None

draw_params = dict(matchColor = (0,255,0), # draw matches in green color
 singlePointColor = None,
 matchesMask = matchesMask, # draw only inliers
 flags = 2)
 
img3 = cv.drawMatches(img1, kpts, img2, kpts2,good,None,**draw_params)

# cv.imwrite("img1.jpg", img1)
# cv.imwrite("img2.jpg", img2)
# cv.imwrite("img3.jpg", img3)
 
plt.imshow(img3, 'gray'),plt.show()





e1 = cv.getTickCount()
# your code execution
e2 = cv.getTickCount()
time = (e2 - e1)/ cv.getTickFrequency()
print(time)


cv.useOptimized()


img = images[4].copy()
gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)
gray = np.float32(gray)

dst = cv.cornerHarris(gray, 2, 3, 0.04)

#result is dilated for marking the corners, not important
dst = cv.dilate(dst,None)


# # Threshold for an optimal value, it may vary depending on the image.
img[dst>.05*dst.max()]=[0,0,255]

display_image(img)


img = images[4].copy()
gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)

corners = cv.goodFeaturesToTrack(gray, 50, 0.01, 5)

corners = np.intp(corners)
 
for i in corners:
 x,y = i.ravel()
 cv.circle(img,(x,y),3,255,-1)
 
plt.imshow(img),plt.show()



